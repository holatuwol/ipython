{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Math 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next important thing we want you to understand is the math behind the cost function(s) that might be applied when performing linear regression. That will be our next lesson.\n",
    "\n",
    "* [Usual assumptions for linear regression](http://stats.stackexchange.com/questions/16381/what-is-a-complete-list-of-the-usual-assumptions-for-linear-regression)\n",
    "* Convexity of cost functions\n",
    "* Stochastic gradient descent\n",
    "* Different interpretations of distance (euclidean, etc.)\n",
    "* Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint: Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications: Search Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretend you have tens of thousands of documents stored in a search index. When an end user enters a search query, what you'd like to do is list what will hopefully be a subset of those documents in a way that will make them feel relevant to the end user.\n",
    "\n",
    "We can answer a substantial amount of the search question by simply filtering the documents down to just the subset that contain the terms entered by the end user. It's important to note that this may result in false negatives (because sometimes documents contain synonyms of words rather than exact words), but we will temporarily accept that as a limitation, because we'll need additional math in order to overcome it.\n",
    "\n",
    "* [Elasticsearch Bool Query](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-bool-query.html)\n",
    "\n",
    "However, even acknowledging that there are false negatives, there may be thousands of documents that match, and you can't just blindly provide all the documents, because there's no way for the end user to consume that much information!\n",
    "\n",
    "One solution that stands out is that maybe you can *summarize* them. Techniques include presenting summary statistics as numbers, presenting data visualizations that condense the results into graphs or other forms that humans can more readily interpret (such as rendering addresses as points on a map), or allowing the end user to \"drill down\" into the search results with facets.\n",
    "\n",
    "* [Core Concepts in Data Analysis: Summarization, Correlation, and Visualization](https://www.researchgate.net/publication/232282057_Core_Concepts_in_Data_Analysis_Summarization_Correlation_and_Visualization)\n",
    "\n",
    "However, this requires you to know a lot about the documents you're getting back, because as you've seen through this example of data exploration for linear regression, how you can summarize the information depends entirely on what kind of data it is.\n",
    "\n",
    "What if we wanted a more generic way to respond to almost all queries? One such generic way to respond to the query is to provide the documents in descending order of *relevance*. This theoretically optimizes the time a user must spend finding the result, because the documents they need most will be presented to them immediately.\n",
    "\n",
    "Relevance, however, is an abstract concept. You can't actually have the end user tell how they feel about each of your tens of thousands of documents, and even if you could, those values aren't static over time. If I searched for \"liferay\" back in 2007, I might expect to get results back on how to install Liferay Portal 4.4. If I searched for \"liferay\" today, I'd think that same document is not at all relevant to my interests.\n",
    "\n",
    "So what can we do instead? We can create a *proxy* for relevance which we will call a *score*.\n",
    "\n",
    "To summarize, our goal now is to create a model that will predict the appropriate *score* for each document, given the context of the search query that the user entered. In Elasticsearch, it turns out that this model is very close to being a *linear combination* of variables derived by performing sparse matrix multiplications of the query vector and the document vectors.\n",
    "\n",
    "* [Elasticsearch Scoring Theory](https://www.elastic.co/guide/en/elasticsearch/guide/current/scoring-theory.html)\n",
    "\n",
    "Once we advance our math further, we'll talk about these derived variables in more detail. However, among these variables is something we already understand now that we've finished regression: a *linear combination* of per-field subscores.\n",
    "\n",
    "* [Elasticsearch Query-Time Boosting](https://www.elastic.co/guide/en/elasticsearch/guide/current/query-time-boosting.html)\n",
    "\n",
    "Knowing that, how then can you find the appropriate boosting that will give you the desired ordering of search results?\n",
    "\n",
    "From this exercise with linear regression, you might already have some ideas on how to derive a model that is predicting something based on a linear combination of weights, and you'll know how to make the model more meaningful by adding new explanatory variables.\n",
    "\n",
    "Just one thing missing. In order to derive the weights (beyond gut instinct choices), you'll need to take a representative subset of your documents and a representative subset of your queries and manually score them in order to allow the model to have something to predict.\n",
    "\n",
    "* [CACM Corpus](http://www.search-engines-book.com/collections/) (free)\n",
    "* [Web Research Collections](http://ir.dcs.gla.ac.uk/test_collections/access_to_data.html) (non-free)\n",
    "\n",
    "However, knowing how much work this is, you can also approximate score by instead simply providing a binary value to each document indicating is it relevant (using a subjective threshold of relevance). With this simpler data set, you would instead predict the probability that the document is relevant and use that as an approximation of a score.\n",
    "\n",
    "In predicting the probability that something belongs to a class rather than predicting a raw score, we transform this from a classic linear regression to binary logistic regression.\n",
    "\n",
    "* [Logistic Regression](https://onlinecourses.science.psu.edu/stat504/node/149)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you have now become curious about linear regression.\n",
    "\n",
    "You might wonder about simple extensions to linear regression, such as linear spline regression where you have boundary points where the coefficients completely change.\n",
    "\n",
    "* [An Introduction to Splines](http://www.statpower.net/Content/313/Lecture%20Notes/Splines.pdf)\n",
    "\n",
    "You might also wonder why we talked about cost functions at the start and if choosing a different cost function might change the way the regression works.\n",
    "\n",
    "* [Quantile Regression: An Introduction](http://www.econ.uiuc.edu/~roger/research/intro/rq3.pdf)\n",
    "\n",
    "It's likely that you've also been wondering about applying transformations of the input and output variables in order to overcome the constraints of the linear relationship between variables.\n",
    "\n",
    "* [Transformations in Regression](http://people.stern.nyu.edu/jsimonof/classes/2301/pdf/transfrm.pdf)\n",
    "\n",
    "You might be able to follow examples of people looking at input types that we haven't talked about (such as geospatial data) that will allow you to apply linear regression to other problems that involve the prediction of a continuous variable with range $(-\\infty, \\infty)$.\n",
    "\n",
    "* [AirBnb Properties in Boston](https://github.com/ResidentMario/boston-airbnb-geo/blob/master/notebooks/boston-airbnb-geo.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
